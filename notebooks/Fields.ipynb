{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping rows with NaN values: 10089\n",
      "After dropping rows with NaN 1584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Fields_lessColumns.csv\")\n",
    "\n",
    "# df = df.loc[df['locality'] == 'Bucuresti']\n",
    "\n",
    "del df['_id'] \n",
    "del df['locality']\n",
    "del df['Unnamed: 0'] # dafaq is this column? delete it...\n",
    "del df['Unnamed: 0.1']\n",
    "\n",
    "# del df['district']\n",
    "del df['landType']\n",
    "del df['landClassification']\n",
    "# del df['frontStradal']\n",
    "# del df['noFronturi']\n",
    "\n",
    "df[\"landArea\"] = pd.to_numeric(df[\"landArea\"], errors='coerce')\n",
    "df = df.loc[df['landArea'] > 1000]\n",
    "\n",
    "print(f'Before droping rows with NaN values: {len(df)}')\n",
    "df.dropna(inplace=True)\n",
    "print(f'After dropping rows with NaN {len(df)}')\n",
    "\n",
    "target = df['price']\n",
    "del df['price']\n",
    "\n",
    "# districts_one_hot = pd.get_dummies(df.district)\n",
    "# df = df.join(districts_one_hot)\n",
    "del df[\"district\"]\n",
    "\n",
    "df['contructionOnLand'] = df['contructionOnLand'].replace({\n",
    "    \"Da\":1,\n",
    "    \"Nu\": 0\n",
    "})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landArea</th>\n",
       "      <th>frontStradal</th>\n",
       "      <th>noFronturi</th>\n",
       "      <th>contructionOnLand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>2516.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>14320.0</td>\n",
       "      <td>142.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>5400.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>7965.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>8440.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>2360.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1289.0</td>\n",
       "      <td>27.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      landArea  frontStradal  noFronturi  contructionOnLand\n",
       "4562    2516.0         30.00         1.0                  0\n",
       "4909   14320.0        142.00         2.0                  0\n",
       "224     1800.0         22.70         2.0                  0\n",
       "4154    5400.0         43.00         2.0                  0\n",
       "4259    7965.0         26.00         2.0                  0\n",
       "...        ...           ...         ...                ...\n",
       "1563   14000.0         73.00         2.0                  0\n",
       "501     8440.0         46.00         1.0                  0\n",
       "1053    2360.0         94.00         2.0                  0\n",
       "3616   13000.0         25.00         1.0                  0\n",
       "4272    1289.0         27.38         1.0                  1\n",
       "\n",
       "[317 rows x 4 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=3)\n",
    "X_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30696320665076693 0.08605384203494382\n",
      "129800.0 [270595.30150662]\n",
      "7160000.0 [762252.17047033]\n",
      "32000.0 [233529.89660421]\n",
      "648000.0 [361862.40952277]\n",
      "310635.0 [351194.83925515]\n",
      "15999.0 [212358.76977205]\n",
      "105000.0 [296658.34460274]\n",
      "1322500.0 [464386.18883985]\n",
      "275000.0 [482139.99647194]\n",
      "129800.0 [270595.30150662]\n"
     ]
    }
   ],
   "source": [
    "X_test = poly_features.fit_transform(X_test)\n",
    "print(reg.score(X_train, y_train), reg.score(X_test, y_test))\n",
    "for i in range(10):\n",
    "    print(y_test.values[i] , reg.predict([X_test[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586614277485027 0.19227800000287543\n",
      "129800.0 [140029.469] [-10229.469]\n",
      "7160000.0 [936435.31802] [6223564.68198]\n",
      "32000.0 [120791.97007] [-88791.97007]\n",
      "648000.0 [629766.52131] [18233.47869]\n",
      "310635.0 [310040.71113333] [594.28886667]\n",
      "15999.0 [56359.87928571] [-40360.87928571]\n",
      "105000.0 [351974.28284] [-246974.28284]\n",
      "1322500.0 [539258.34827619] [783241.65172381]\n",
      "275000.0 [411576.84066667] [-136576.84066667]\n",
      "129800.0 [140029.469] [-10229.469]\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))\n",
    "for i in range(10):\n",
    "    print(y_test.values[i] , rf.predict([X_test[i]]), y_test.values[i] - rf.predict([X_test[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29800e+05 1.05000e+06 1.76750e+05 7.50000e+05 1.00000e+06 2.20000e+04\n",
      " 3.50000e+04 9.90000e+05 2.36712e+05 1.29800e+05 1.22160e+05 7.50000e+04\n",
      " 4.20000e+04 9.50000e+04 2.07000e+05 9.00000e+04 1.25000e+05 8.00000e+05\n",
      " 1.08000e+05 4.20000e+04 4.60000e+04 9.00000e+05 2.00000e+05 2.88000e+05\n",
      " 1.50000e+05 1.50000e+05 9.00000e+04 4.50000e+04 9.60000e+04 8.00000e+04\n",
      " 1.11300e+05 1.93500e+06 8.00000e+05 4.00000e+05 6.50000e+05 1.20000e+05\n",
      " 1.80000e+04 4.20000e+04 1.90000e+05 3.00000e+05 4.58800e+05 8.00000e+05\n",
      " 9.00000e+04 6.22500e+05 1.80000e+04 4.00000e+05 2.25000e+05 9.10000e+05\n",
      " 3.90000e+06 3.00000e+04 2.60000e+05 2.40000e+04 6.30000e+05 2.40000e+04\n",
      " 9.00000e+04 2.88000e+05 4.25000e+04 3.90000e+04 1.20000e+05 2.40000e+04\n",
      " 1.31200e+05 1.62000e+05 4.50000e+04 9.90000e+05 3.80000e+04 2.22500e+05\n",
      " 7.50000e+04 8.10000e+04 4.00000e+05 4.50000e+04 1.30000e+05 3.29000e+06\n",
      " 2.20000e+05 6.00000e+04 7.35000e+05 1.36000e+05 2.00000e+05 9.99000e+05\n",
      " 9.00000e+04 6.00000e+05 9.00000e+04 9.00000e+04 4.50000e+05 7.48000e+05\n",
      " 5.75000e+05 2.00000e+05 3.26667e+05 1.96000e+05 6.30000e+04 2.00000e+04\n",
      " 9.00000e+04 5.35743e+05 2.50000e+05 1.80000e+05 5.50000e+04 3.90000e+04\n",
      " 1.22500e+05 9.60000e+04 1.20000e+05 1.50000e+05 3.00000e+05 1.00000e+05\n",
      " 4.60000e+04 1.30000e+05 2.00000e+05 5.88000e+04 8.40000e+05 3.90000e+04\n",
      " 6.40000e+04 1.50000e+05 1.40000e+05 5.00000e+04 3.78000e+05 9.00000e+04\n",
      " 6.80000e+04 3.90000e+06 5.50000e+05 3.50000e+04 1.20000e+05 1.50000e+05\n",
      " 1.22388e+05 2.40000e+04 4.58800e+05 8.40000e+04 2.28000e+05 5.00000e+05\n",
      " 2.80000e+04 4.50000e+05 1.50000e+05 3.78000e+05 1.11300e+05 3.12000e+05\n",
      " 9.00000e+04 4.00000e+05 1.54000e+06 9.00000e+04 2.90000e+06 2.09000e+05\n",
      " 2.25000e+05 8.50000e+04 3.00000e+05 4.50000e+04 1.50000e+05 4.80000e+04\n",
      " 3.92000e+04 3.90000e+04 1.00000e+05 8.50000e+04 2.40000e+04 2.20000e+05\n",
      " 6.50000e+05 2.76000e+05 9.60000e+04 3.80000e+05 6.50000e+05 4.40000e+05\n",
      " 1.56000e+05 3.30000e+04 6.99000e+04 1.50000e+05 1.30000e+05 3.01300e+05\n",
      " 3.80000e+04 4.20000e+05 1.20000e+05 1.00000e+05 1.92500e+05 6.90000e+04\n",
      " 7.50000e+05 1.65000e+05 3.75000e+05 1.35000e+05 3.90000e+05 1.54000e+06\n",
      " 7.80000e+04 1.20000e+05 6.00000e+04 9.00000e+05 2.20000e+05 1.41750e+06\n",
      " 3.20000e+05 2.50000e+06 3.12000e+05 1.50000e+05 1.30000e+05 3.00000e+05\n",
      " 2.88000e+05 1.30000e+04 3.36000e+05 2.50000e+05 3.15000e+05 2.20000e+05\n",
      " 2.00000e+04 3.50000e+04 1.50000e+06 4.80000e+04 6.40000e+04 5.60000e+04\n",
      " 3.84000e+05 5.00000e+05 2.09000e+05 9.00000e+04 6.60000e+05 5.60000e+04\n",
      " 1.25000e+05 1.50000e+05 5.88000e+04 4.50000e+04 2.80000e+05 6.32500e+05\n",
      " 2.70000e+05 1.65000e+05 6.30000e+05 9.67750e+04 2.00000e+05 2.60000e+05\n",
      " 1.25000e+05 4.80000e+04 1.79000e+05 9.00000e+04 1.56000e+05 6.60000e+05\n",
      " 8.10000e+04 3.50000e+05 7.50000e+04 1.50000e+05 9.00000e+04 6.32500e+05\n",
      " 3.80000e+05 0.00000e+00 8.60000e+04 1.80000e+05 8.50000e+04 1.53000e+05\n",
      " 5.00000e+05 3.00000e+04 2.00000e+05 6.30000e+04 3.50000e+04 8.60000e+04\n",
      " 2.20000e+06 2.50000e+04 1.12000e+05 1.50000e+06 1.43880e+06 1.08000e+05\n",
      " 1.20000e+05 1.00000e+05 7.99000e+05 1.50000e+05 1.00000e+05 3.50000e+04\n",
      " 1.30000e+05 1.53000e+05 2.50000e+06 2.50000e+06 8.90000e+04 1.50000e+06\n",
      " 6.30000e+05 9.00000e+04 1.40000e+04 9.00000e+04 9.77500e+04 3.50000e+05\n",
      " 1.44000e+06 1.30000e+05 2.40000e+04 6.90000e+05 1.40000e+04 1.95000e+05\n",
      " 8.50000e+04 5.00000e+04 6.60000e+05 1.96000e+05 3.00000e+05 1.00000e+05\n",
      " 5.48622e+04 2.50000e+05 1.75000e+04 4.30000e+04 1.52000e+05 1.03500e+06\n",
      " 1.36352e+05 8.00000e+03 1.40000e+05 1.50000e+06 1.50000e+05 1.50000e+03\n",
      " 3.80000e+05 1.20000e+05 2.70000e+05 3.20000e+05 2.50000e+06 9.60000e+04\n",
      " 1.36352e+05 9.00000e+04 1.80800e+05 2.00000e+05 1.20000e+05 2.25000e+05\n",
      " 1.20000e+05 4.50000e+04 1.50000e+05 1.60000e+05 3.90000e+06 3.75000e+05\n",
      " 1.80000e+05 1.50000e+05 1.80800e+05 6.72000e+04 1.30000e+05 9.00000e+04\n",
      " 2.00200e+06 1.35000e+05 5.06000e+05 3.01300e+05 1.50000e+05]\n",
      "129800.0 129800.0 0.0\n",
      "7160000.0 1050000.0 6110000.0\n",
      "32000.0 176750.0 -144750.0\n",
      "648000.0 750000.0 -102000.0\n",
      "310635.0 1000000.0 -689365.0\n",
      "15999.0 22000.0 -6001.0\n",
      "105000.0 35000.0 70000.0\n",
      "1322500.0 990000.0 332500.0\n",
      "275000.0 236712.0 38288.0\n",
      "129800.0 129800.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "for i in range(10):\n",
    "    print(y_test.values[i] , predictions[i], y_test.values[i] - predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoders tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['Female', 1], ['Male', 4]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_Female', 'gender_Male', 'plm_1', 'plm_2', 'plm_3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names(['gender', 'plm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
